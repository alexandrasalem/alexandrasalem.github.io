
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Alexandra Salem is a Research Data Analyst for the Oregon Health \u0026amp; Science University. She has a MS in Computer Science. Her research interests include machine learning, natural language processing, and language disorders such as aphasia.\n","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Alexandra Salem is a Research Data Analyst for the Oregon Health \u0026 Science University. She has a MS in Computer Science. Her research interests include machine learning, natural language processing, and language disorders such as aphasia.","tags":null,"title":"Alexandra Salem, MS","type":"authors"},{"authors":["Alexandra C. Salem","Robert C. Gale","Mikala Fleegle","Gerasimos Fergadiotis","Steven Bedrick"],"categories":[],"content":"","date":1702252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676920675,"objectID":"a195d729977b2ab5ea99f88cfbec5541","permalink":"https://alexandrasalem.com/publication/salem-identification-2023/","publishdate":"2023-02-20T19:17:55.52985Z","relpermalink":"/publication/salem-identification-2023/","section":"publication","summary":"**Purpose**: To date, there are no automated tools for the identification and fine-grained classification of paraphasias within discourse, the production of which is the hallmark characteristic of most people with aphasia (PWA). In this work, we fine-tune a large language model (LLM) to automatically predict paraphasia targets in Cinderella story retellings. **Method**: Data consisted of 332 Cinderella story retellings containing 2,489 paraphasias from PWA, for which research assistants identified their intended targets. We supplemented these training data with 256 sessions from control participants, to which we added 2,415 synthetic paraphasias. We conducted four experiments using different training data configurations to fine-tune the LLM to automatically 'fill in the blank' of the paraphasia with a predicted target, given the context of the rest of the story retelling. We tested the experiments' predictions against our human-identified targets and stratified our results by ambiguity of the targets and clinical factors. **Results**: The model trained on controls and PWA achieved 50.7% accuracy at exactly matching the human-identified target. Fine-tuning on PWA data, with or without controls, led to comparable performance. The model performed better on targets with less human ambiguity and on paraphasias from participants with fluent or less severe aphasia. **Conclusions**: We were able to automatically identify the intended target of paraphasias in discourse using just the surrounding language about half of the time. These findings take us a step closer to automatic aphasic discourse analysis. In future work, we will incorporate phonological information from the paraphasia to further improve predictive utility.","tags":[],"title":"Automating Intended Target Identification for Paraphasias in Discourse Using a Large Language Model","type":"publication"},{"authors":["Alexandra Salem","Mikala Fleegle","Robert Gale","Gerasimos Fergadiotis","Steven Bedrick"],"categories":null,"content":"","date":1685634300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685634300,"objectID":"1e6e4c8896db10c970c32390aa50ece1","permalink":"https://alexandrasalem.com/talk/cac-2023/","publishdate":"2023-06-01T15:45:00Z","relpermalink":"/talk/cac-2023/","section":"event","summary":"Automating intended target identification for paraphasias in discourse using a large language model","tags":[],"title":"CAC 2023","type":"event"},{"authors":["Robert C. Gale","Alexandra C. Salem","Gerasimos Fergadiotis","Steven Bedrick"],"categories":[],"content":"","date":1676920675,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676920675,"objectID":"0c868945aee840d6d7bc3b0a43698f57","permalink":"https://alexandrasalem.com/publication/gale-bort-2023/","publishdate":"2023-02-20T19:17:55.52985Z","relpermalink":"/publication/gale-bort-2023/","section":"publication","summary":"Speech language pathologists rely on information spanning the layers of language, often drawing from multiple layers (e.g. phonology \u0026 semantics) at once. Recent innovations in large language models (LLMs) have been shown to build powerful representations for many complex language structures, especially syntax and semantics, unlocking the potential of large datasets through self-supervised learning techniques. However, these datasets are overwhelmingly orthographic, favoring writing systems like the English alphabet, a natural but phonetically imprecise choice. Meanwhile, LLM support for the international phonetic alphabet (IPA) ranges from poor to absent. Further, LLMs encode text at a word- or near-word level, and pre-training tasks have little to gain from phonetic/phonemic representations. In this paper, we introduce BORT, an LLM for mixed orthography/IPA meant to overcome these limitations. To this end, we extend the pre-training of an existing LLM with our own self-supervised pronunciation tasks. We then fine-tune for a clinical task that requires simultaneous phonological and semantic analysis. For an ‚Äúeasy‚Äù and ‚Äúhard‚Äù version of these tasks, we show that fine-tuning from our models is more accurate by a relative 24% and 29%, and improved on character error rates by a relative 75% and 31%, respectively, than those starting from the original model.","tags":[],"title":"Mixed Orthographic/Phonemic Language Modeling: Beyond Orthographically Restricted Transformers (BORT)","type":"publication"},{"authors":["Alexandra C. Salem","Robert Gale","Marianne Casilio","Mikala Fleegle","Gerasimos Fergadiotis","Steven Bedrick"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676920675,"objectID":"6aff9858b33536c5b6bb6a54392d56c9","permalink":"https://alexandrasalem.com/publication/salem-refining-2022/","publishdate":"2023-02-20T19:17:55.52985Z","relpermalink":"/publication/salem-refining-2022/","section":"publication","summary":"**Purpose**:  ParAlg (Paraphasia Algorithms) is a software that automatically categorizes a person with aphasia's naming error (paraphasia) in relation to its intended target on a picture-naming test. These classifications (based on lexicality as well as semantic, phonological, and morphological similarity to the target) are important for characterizing an individual's word-finding deficits or anomia. In this study, we applied a modern language model called BERT (Bidirectional Encoder Representations from Transformers) as a semantic classifier and evaluated its performance against ParAlg's original word2vec model.\n\n\n**Method**:  We used a set of 11,999 paraphasias produced during the Philadelphia Naming Test. We trained ParAlg with word2vec or BERT and compared their performance to humans. Finally, we evaluated BERT's performance in terms of word-sense selection and conducted an item-level discrepancy analysis to identify which aspects of semantic similarity are most challenging to classify.\n\n\n**Results**:  Compared with word2vec, BERT qualitatively reduced word-sense issues and quantitatively reduced semantic classification errors by almost half. A large percentage of errors were attributable to semantic ambiguity. Of the possible semantic similarity subtypes, responses that were associated with or category coordinates of the intended target were most likely to be misclassified by both models and humans alike.\n\n\n**Conclusions**:  BERT outperforms word2vec as a semantic classifier, partially due to its superior handling of polysemy. This work is an important step for further establishing ParAlg as an accurate assessment tool.","tags":[],"title":"Refining Semantic Similarity of Paraphasias Using a Contextual Language Model","type":"publication"},{"authors":["Alexandra Salem","Robert Gale","Gerasimos Fergadiotis","Steven Bedrick"],"categories":null,"content":"","date":1635078600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635078600,"objectID":"9a5a8b8fc5d18db3c85db1c73a69c5c6","permalink":"https://alexandrasalem.com/talk/aoa-2021/","publishdate":"2021-10-24T12:30:00Z","relpermalink":"/talk/aoa-2021/","section":"event","summary":"Improving Automatic Semantic Similarity Classification of the PNT","tags":[],"title":"AoA 2021","type":"event"},{"authors":["Alexandra C. Salem","Heather MacFarlane","Joel R. Adams","Grace O. Lawley","Jill K. Dolata","Steven Bedrick","Eric Fombonne"],"categories":[],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676921251,"objectID":"ae7f4a202b40b770ecaf37c33e26b79c","permalink":"https://alexandrasalem.com/publication/salem-evaluating-2021/","publishdate":"2023-02-20T19:27:30.660573Z","relpermalink":"/publication/salem-evaluating-2021/","section":"publication","summary":"Measurement of language atypicalities in Autism Spectrum Disorder (ASD) is cumbersome and costly. Better language outcome measures are needed. Using language transcripts, we generated Automated Language Measures (ALMs) and tested their validity. 169 participants (96 ASD, 28 TD, 45 ADHD) ages 7 to 17 were evaluated with the Autism Diagnostic Observation Schedule. Transcripts of one task were analyzed to generate seven ALMs: mean length of utterance in morphemes, number of different word roots (NDWR), um proportion, content maze proportion, unintelligible proportion, c-units per minute, and repetition proportion. With the exception of repetition proportion (p=.07), nonparametric ANOVAs showed significant group differences (p\u003c0.01). The TD and ADHD groups did not differ from each other in post-hoc analyses. With the exception of NDWR, the ASD group showed significantly (p\u003c0.01) lower scores than both comparison groups. The ALMs were correlated with standardized clinical and language evaluations of ASD. In age- and IQ-adjusted logistic regression analyses, four ALMs significantly predicted ASD status with satisfactory accuracy (67.9‚Äì75.5%). When ALMs were combined together, accuracy improved to 82.4%. These ALMs offer a promising approach for generating novel outcome measures.","tags":[],"title":"Evaluating atypical language in autism using automated language measures","type":"publication"},{"authors":["Alexandra Salem, MS","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://alexandrasalem.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":null,"categories":["R"],"content":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA ) Figure 1: A fancy pie chart.\n","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"84a876ba789bb7232be8d9ed2487fd98","permalink":"https://alexandrasalem.com/post/2020-12-01-r-rmarkdown/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/post/2020-12-01-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://alexandrasalem.com/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Alexandra Salem, MS"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post‚Äôs folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://alexandrasalem.com/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"}]